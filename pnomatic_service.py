import re
import os
import json
import io
import cv2
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
import PyPDF2
import pytesseract
from PIL import Image
import pandas as pd
from dataclasses import dataclass, asdict
import logging
import math
from collections import Counter
import fitz  # PyMuPDF for better PDF handling
from flask import Flask, request, jsonify, current_app
from werkzeug.utils import secure_filename
import pdf2image

# ============================================
# DATABASE IMPORTS (YENÄ°)
# ============================================
from database import db, init_db
from db_loader import load_service_config

# ============================================
# CONFIG IMPORT (YENÄ°)
# ============================================
from config import Config

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ComponentDetection:
    """Detected component information"""
    component_type: str
    label: str
    position: Tuple[int, int]
    confidence: float
    bounding_box: Tuple[int, int, int, int]
    
@dataclass
class CircuitAnalysisResult:
    """Analysis result for each criterion"""
    criteria_name: str
    found: bool
    content: str
    score: float
    max_score: float
    details: Dict[str, Any]
    visual_evidence: List[ComponentDetection]

class PneumaticCircuitAnalyzer:
    """GeliÅŸmiÅŸ pnÃ¶matik devre ÅŸemasÄ± analiz sistemi"""
    
    def __init__(self, app=None):
        logger.info("PnÃ¶matik Devre ÅemasÄ± analiz sistemi baÅŸlatÄ±lÄ±yor...")
        
        # Flask app context varsa DB'den yÃ¼kle, yoksa boÅŸ baÅŸlat
        if app:
            with app.app_context():
                try:
                    config = load_service_config('pneumatic_circuit')
                    
                    # DB'den yÃ¼klenen veriler
                    self.pneumatic_criteria_weights = config.get('criteria_weights', {})
                    self.pneumatic_criteria_details = config.get('criteria_details', {})
                    self.pattern_definitions = config.get('pattern_definitions', {})
                    self.validation_keywords = config.get('validation_keywords', {})
                    self.category_actions = config.get('category_actions', {})
                    
                    # visual_templates pattern_definitions iÃ§inde
                    self.visual_templates = self.pattern_definitions.get('visual_templates', {})
                    
                    logger.info(f"âœ… VeritabanÄ±ndan yÃ¼klendi: {len(self.pneumatic_criteria_weights)} kategori")
                    
                except Exception as e:
                    logger.error(f"âš ï¸ VeritabanÄ±ndan yÃ¼kleme baÅŸarÄ±sÄ±z: {e}")
                    logger.warning("âš ï¸ Fallback: BoÅŸ config kullanÄ±lÄ±yor")
                    self.pneumatic_criteria_weights = {}
                    self.pneumatic_criteria_details = {}
                    self.pattern_definitions = {}
                    self.validation_keywords = {}
                    self.category_actions = {}
                    self.visual_templates = {}
        else:
            # Flask app yoksa boÅŸ baÅŸlat
            logger.warning("âš ï¸ Flask app context yok, boÅŸ config kullanÄ±lÄ±yor")
            self.pneumatic_criteria_weights = {}
            self.pneumatic_criteria_details = {}
            self.pattern_definitions = {}
            self.validation_keywords = {}
            self.category_actions = {}
            self.visual_templates = {}

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDF'den metin Ã§Ä±karma (geliÅŸmiÅŸ)"""
        try:
            text = ""
            # PyMuPDF ile daha iyi metin Ã§Ä±karma
            doc = fitz.open(pdf_path)
            for page in doc:
                text += page.get_text() + "\n"
            doc.close()
            
            # Fallback olarak PyPDF2 kullan
            if not text.strip():
                with open(pdf_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    for page in pdf_reader.pages:
                        text += page.extract_text() + "\n"
            
            # Metin normalleÅŸtirme
            text = re.sub(r'\s+', ' ', text)
            text = text.replace('|', ' ')
            text = text.replace('Ã¢â‚¬"', '-')
            text = text.replace('"', '"').replace('"', '"')
            return text.strip()
            
        except Exception as e:
            logger.error(f"PDF metin Ã§Ä±karma hatasÄ±: {e}")
            return ""

    def extract_text_from_image(self, image_path: str) -> str:
        """GeliÅŸmiÅŸ OCR ile metin Ã§Ä±karma"""
        try:
            img = cv2.imread(image_path)
            if img is None:
                return ""
            
            # GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # Kontrast artÄ±rma
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # GÃ¼rÃ¼ltÃ¼ azaltma
            denoised = cv2.medianBlur(enhanced, 3)
            
            # Thresholding
            _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # Morfolojik iÅŸlemler
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))
            morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            
            # OCR yapÄ±landÄ±rmasÄ± - TÃ¼rkÃ§e ve Ä°ngilizce karakter desteÄŸi
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼. '
            
            # OCR uygulama
            text = pytesseract.image_to_string(morph, lang='tur+eng', config=custom_config)
            
            # Alternatif threshold ile tekrar dene
            if len(text.strip()) < 10:
                _, thresh2 = cv2.threshold(denoised, 127, 255, cv2.THRESH_BINARY)
                text2 = pytesseract.image_to_string(thresh2, lang='tur+eng', config=custom_config)
                if len(text2.strip()) > len(text.strip()):
                    text = text2
            
            # Temizleme
            text = re.sub(r'[^\w\s\.\-\(\)\[\]\{\}\+\=\*\/]', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            
            return text
            
        except Exception as e:
            logger.error(f"GeliÅŸmiÅŸ OCR hatasÄ±: {e}")
            return ""

    def detect_visual_components(self, image_path: str) -> List[ComponentDetection]:
        """Ã‡ok geliÅŸmiÅŸ gÃ¶rsel bileÅŸen tespiti - daha geniÅŸ algÄ±lama"""
        detections = []
        try:
            img = cv2.imread(image_path)
            if img is None:
                return detections
            
            # GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # Kontrast artÄ±rma
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # GÃ¼rÃ¼ltÃ¼ azaltma
            denoised = cv2.medianBlur(enhanced, 3)
            
            # Kenar tespiti
            edges = cv2.Canny(denoised, 30, 100)
            
            # Morfolojik iÅŸlemler
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
            dilated = cv2.dilate(edges, kernel, iterations=1)
            
            # Kontur bulma - daha geniÅŸ arama
            contours, hierarchy = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            
            # Åekil analizi iÃ§in Ã§ok daha geniÅŸ filtreler
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                if area < 20:  # Ã‡ok daha dÃ¼ÅŸÃ¼k minimum alan
                    continue
                    
                # Kontur Ã¶zelliklerini hesapla
                perimeter = cv2.arcLength(contour, True)
                if perimeter == 0:
                    continue
                    
                # Åekil analizi
                approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h if h > 0 else 0
                extent = area / (w * h) if w * h > 0 else 0
                solidity = area / cv2.contourArea(cv2.convexHull(contour)) if cv2.contourArea(cv2.convexHull(contour)) > 0 else 0
                
                component_type = "unknown"
                confidence = 0.2  # Daha dÃ¼ÅŸÃ¼k baÅŸlangÄ±Ã§ gÃ¼veni
                
                # Ã‡ok daha geniÅŸ pnÃ¶matik sembol analizi
                if len(approx) == 4:  # DÃ¶rtgen
                    if 0.7 < aspect_ratio < 1.4:  # Kare benzeri - vana
                        component_type = "valve"
                        confidence = 0.7
                    elif aspect_ratio > 1.5:  # Uzun dikdÃ¶rtgen - silindir
                        component_type = "cylinder"
                        confidence = 0.8
                    elif aspect_ratio < 0.7:  # Dikey dikdÃ¶rtgen - filtre/regÃ¼latÃ¶r
                        component_type = "filter"
                        confidence = 0.6
                    else:  # Genel dÃ¶rtgen
                        component_type = "component"
                        confidence = 0.5
                elif len(approx) == 3:  # ÃœÃ§gen - akÄ±ÅŸ kontrol
                    component_type = "flow_control"
                    confidence = 0.6
                elif len(approx) > 10:  # Daire benzeri - baÄŸlantÄ±
                    component_type = "connection"
                    confidence = 0.6
                elif 5 <= len(approx) <= 10:  # Ã‡okgen - Ã§eÅŸitli bileÅŸenler
                    component_type = "component"
                    confidence = 0.4
                else:
                    # Ã–zel pnÃ¶matik semboller iÃ§in Ã§ok daha geniÅŸ kontroller
                    if 1.2 < aspect_ratio < 4.0 and extent > 0.6:  # Silindir sembolÃ¼
                        component_type = "cylinder"
                        confidence = 0.7
                    elif aspect_ratio > 4.0:  # BaÄŸlantÄ± hattÄ±
                        component_type = "connection"
                        confidence = 0.5
                    elif solidity > 0.8 and 0.8 < aspect_ratio < 1.2:  # Vana sembolÃ¼
                        component_type = "valve"
                        confidence = 0.6
                    elif area > 100:  # BÃ¼yÃ¼k ÅŸekiller
                        component_type = "component"
                        confidence = 0.4
                
                # Ã‡ok daha geniÅŸ boyut filtresi
                if w > 10 and h > 10:  # Ã‡ok daha kÃ¼Ã§Ã¼k minimum boyut
                    detection = ComponentDetection(
                        component_type=component_type,
                        label=f"{component_type}_{len(detections)+1}",
                        position=(x + w//2, y + h//2),
                        confidence=confidence,
                        bounding_box=(x, y, w, h)
                    )
                    detections.append(detection)
            
            # GÃ¶rsel template eÅŸleÅŸtirme - DB'den
            try:
                templates = self.pattern_definitions.get('templates', {})
                for template_type, symbols in templates.items():
                    for symbol in symbols:
                        ocr_text = self.extract_text_from_image(image_path)
                        if symbol in ocr_text:
                            detection = ComponentDetection(
                                component_type=template_type,
                                label=f"{template_type}_template_{len(detections)+1}",
                                position=(img.shape[1]//2, img.shape[0]//2),
                                confidence=0.4,
                                bounding_box=(0, 0, img.shape[1], img.shape[0])
                            )
                            detections.append(detection)
                            break
            except:
                pass
            
            # Ã‡ift tespiti Ã¶nleme
            unique_detections = []
            seen_positions = set()
            for detection in detections:
                pos_key = (detection.position[0] // 30, detection.position[1] // 30)
                if pos_key not in seen_positions and detection.confidence > 0.2:
                    unique_detections.append(detection)
                    seen_positions.add(pos_key)
            
            # EÄŸer hiÃ§ tespit yoksa, genel bileÅŸen olarak iÅŸaretle
            if not unique_detections and contours:
                for i, contour in enumerate(contours[:10]):
                    area = cv2.contourArea(contour)
                    if area > 50:
                        x, y, w, h = cv2.boundingRect(contour)
                        detection = ComponentDetection(
                            component_type="component",
                            label=f"component_{i+1}",
                            position=(x + w//2, y + h//2),
                            confidence=0.3,
                            bounding_box=(x, y, w, h)
                        )
                        unique_detections.append(detection)
            
            return unique_detections[:30]
            
        except Exception as e:
            logger.error(f"Ã‡ok geliÅŸmiÅŸ gÃ¶rsel bileÅŸen tespiti hatasÄ±: {e}")
            return detections

    def analyze_criteria(self, text: str, ocr_text: str, visual_detections: List[ComponentDetection], category: str) -> Dict[str, CircuitAnalysisResult]:
        """Kriter analizi - daha cÃ¶mert puanlama"""
        results = {}
        criteria = self.pneumatic_criteria_details.get(category, {})
        
        combined_text = f"{text} {ocr_text}".lower()
        
        for criterion_name, criterion_data in criteria.items():
            pattern = criterion_data["pattern"]
            weight = criterion_data["weight"]
            description = criterion_data.get("description", criterion_name) 
            
            # Metin tabanlÄ± eÅŸleÅŸme
            text_matches = re.findall(pattern, combined_text, re.IGNORECASE | re.MULTILINE)
            
            # GÃ¶rsel eÅŸleÅŸme kontrolÃ¼
            visual_matches = []
            if criterion_name in ["silindir_actuator", "yon_kontrol_vanalar", "hava_kaynagi", "hava_hazirlama_grubu"]:
                relevant_detections = [d for d in visual_detections 
                                     if d.component_type in ["cylinder", "valve", "filter", "connection"] and d.confidence > 0.3]
                visual_matches = relevant_detections[:5]
            
            # Puan hesaplama - Ã§ok daha cÃ¶mert algoritma
            base_score = 0
            
            # Metin eÅŸleÅŸmesi iÃ§in puan
            if text_matches:
                text_score = min(weight * 0.9, len(text_matches) * (weight * 0.4))
                base_score += text_score
            
            # GÃ¶rsel eÅŸleÅŸmesi iÃ§in puan
            if visual_matches:
                visual_score = min(weight * 0.6, len(visual_matches) * (weight * 0.25))
                base_score += visual_score
            
            # GÃ¶rsel bileÅŸen varsa minimum puan garantisi
            if visual_detections and len(visual_detections) > 2:
                base_score = max(base_score, weight * 0.4)
            
            # Herhangi bir gÃ¶rsel bileÅŸen varsa bonus puan
            if visual_detections:
                base_score += weight * 0.1
            
            # Ã‡ok eÅŸleÅŸme bonusu
            if len(text_matches) >= 2:
                base_score += weight * 0.15
            
            total_score = min(weight, base_score)
            
            found = len(text_matches) > 0 or len(visual_matches) > 0 or len(visual_detections) > 0
            
            content_parts = []
            if text_matches:
                content_parts.append(f"Metin: {str(text_matches[:3])}")
            if visual_matches:
                content_parts.append(f"GÃ¶rsel: {len(visual_matches)} tespit")
            if visual_detections and not visual_matches:
                content_parts.append(f"GÃ¶rsel BileÅŸenler: {len(visual_detections)} adet")
            
            content = " | ".join(content_parts) if content_parts else "GÃ¶rsel bileÅŸenler algÄ±landÄ±"
            
            results[criterion_name] = CircuitAnalysisResult(
                criteria_name=description,
                found=found,
                content=content,
                score=total_score,
                max_score=weight,
                details={
                    "pattern_used": pattern,
                    "text_matches": len(text_matches),
                    "visual_matches": len(visual_matches),
                    "total_visual_components": len(visual_detections)
                },
                visual_evidence=visual_matches
            )
        
        return results

    def calculate_scores(self, analysis_results: Dict[str, Dict[str, CircuitAnalysisResult]]) -> Dict[str, Any]:
        """Puan hesaplama"""
        category_scores = {}
        total_score = 0
        
        for category, results in analysis_results.items():
            category_max = self.pneumatic_criteria_weights[category]
            category_earned = sum(result.score for result in results.values())
            category_possible = sum(result.max_score for result in results.values())
            
            if category_possible > 0:
                raw_percentage = category_earned / category_possible
                adjusted_percentage = math.pow(raw_percentage, 0.8)
                normalized_score = adjusted_percentage * category_max
            else:
                normalized_score = 0
            
            category_scores[category] = {
                "earned": round(category_earned, 2),
                "possible": category_possible,
                "normalized": round(normalized_score, 2),
                "max_weight": category_max,
                "percentage": round((category_earned / category_possible * 100), 2) if category_possible > 0 else 0
            }
            
            total_score += normalized_score
        
        final_score = min(100, total_score * 1.05)
        
        return {
            "category_scores": category_scores,
            "total_score": round(final_score, 2),
            "total_max_score": 100,
            "overall_percentage": round(final_score, 2)
        }

    def extract_specific_values(self, text: str, ocr_text: str) -> Dict[str, Any]:
        """Ã–zel deÄŸer Ã§Ä±karma - DB'den pattern'ler ile"""
        combined_text = f"{text} {ocr_text}"
        values = {
            "proje_adi": "BelirtilmemiÅŸ",
            "cizim_tarihi": "BelirtilmemiÅŸ",
            "tasarim_tarihi": "BelirtilmemiÅŸ",
            "onay_tarihi": "BelirtilmemiÅŸ",
            "calisma_basinci": "BelirtilmemiÅŸ",
            "sistem_tipi": "BelirtilmemiÅŸ",
            "vana_sayisi": 0,
            "silindir_sayisi": 0,
            "frl_mevcut": False,
            "firma": "BelirtilmemiÅŸ"
        }
        
        # DB'den extract_values pattern'lerini al
        extract_values = self.pattern_definitions.get('extract_values', {})
        
        # Proje adÄ±
        project_patterns = extract_values.get('proje_adi', [])
        for pattern in project_patterns:
            match = re.search(pattern, combined_text, re.IGNORECASE)
            if match:
                values["proje_adi"] = match.group(1) if match.groups() else match.group(0)
                break
        
        # BasÄ±nÃ§ bilgisi
        pressure_patterns = extract_values.get('calisma_basinci', [])
        for pattern in pressure_patterns:
            pressure_match = re.search(pattern, combined_text, re.IGNORECASE)
            if pressure_match:
                values["calisma_basinci"] = f"{pressure_match.group(1)} bar"
                break
        
        # Vana sayÄ±sÄ±
        vana_patterns = extract_values.get('vana_sayisi', [])
        vana_matches = []
        for pattern in vana_patterns:
            matches = re.findall(pattern, combined_text, re.IGNORECASE)
            vana_matches.extend(matches)
        
        rectangle_count = combined_text.lower().count('â–¡') + combined_text.lower().count('â– ')
        if rectangle_count > 0:
            vana_matches.extend(['visual_valve'] * min(rectangle_count, 3))
        
        values["vana_sayisi"] = len(set(vana_matches)) if vana_matches else 0
        
        # Silindir sayÄ±sÄ±
        silindir_patterns = extract_values.get('silindir_sayisi', [])
        silindir_matches = []
        for pattern in silindir_patterns:
            matches = re.findall(pattern, combined_text, re.IGNORECASE)
            silindir_matches.extend(matches)
        
        piston_symbols = combined_text.count('â•') + combined_text.count('â”')
        if piston_symbols > 2:
            silindir_matches.extend(['visual_cylinder'] * min(piston_symbols // 3, 2))
        
        values["silindir_sayisi"] = len(set(silindir_matches)) if silindir_matches else 0
        
        # FRL kontrolÃ¼
        frl_patterns = extract_values.get('frl_mevcut', [])
        for pattern in frl_patterns:
            if re.search(pattern, combined_text, re.IGNORECASE):
                values["frl_mevcut"] = True
                break
        
        # Firma bilgisi
        if "ACT" in combined_text:
            values["firma"] = "ACT"
        elif "FESTO" in combined_text:
            values["firma"] = "FESTO"
        
        return values

    def extract_project_information(self, text: str, ocr_text: str) -> Dict[str, Any]:
        """Proje bilgilerini Ã§Ä±karÄ±r - DB'den"""
        combined_text = f"{text} {ocr_text}"
        project_info = {}
        
        extract_values = self.pattern_definitions.get('extract_values', {})
        
        # Created by
        created_patterns = extract_values.get('created_by', [])
        for pattern in created_patterns:
            match = re.search(pattern, combined_text, re.IGNORECASE)
            if match:
                project_info["created_by"] = match.group(1).strip()
                break
        
        # Checked by
        checked_patterns = extract_values.get('checked_by', [])
        for pattern in checked_patterns:
            match = re.search(pattern, combined_text, re.IGNORECASE)
            if match:
                project_info["checked_by"] = match.group(1).strip()
                break
        
        # Approved by
        approved_patterns = extract_values.get('approved_by', [])
        for pattern in approved_patterns:
            match = re.search(pattern, combined_text, re.IGNORECASE)
            if match:
                project_info["approved_by"] = match.group(1).strip()
                break
        
        return project_info

    def generate_recommendations(self, analysis_results: Dict, scores: Dict, extracted_values: Dict) -> List[str]:
        """Ã–neri Ã¼retimi"""
        recommendations = []
        
        overall_score = scores["overall_percentage"]
        
        # Genel deÄŸerlendirme
        if overall_score >= 80:
            recommendations.append("âœ… Ã‡Ä°ZÄ°M KALÄ°TESÄ°: MÃ¼kemmel")
        elif overall_score >= 70:
            recommendations.append("âœ… Ã‡Ä°ZÄ°M KALÄ°TESÄ°: Ä°yi")
        elif overall_score >= 60:
            recommendations.append("âš ï¸ Ã‡Ä°ZÄ°M KALÄ°TESÄ°: Orta")
        else:
            recommendations.append("âŒ Ã‡Ä°ZÄ°M KALÄ°TESÄ°: Yetersiz")
        
        recommendations.append(f"ğŸ“Š Toplam Puan: {overall_score:.1f}/100")
        
        # Kategori bazÄ±nda Ã¶neriler
        for category, results in analysis_results.items():
            category_score = scores["category_scores"][category]["percentage"]
            
            if category_score < 50:
                recommendations.append(f"âŒ {category}: Ciddi eksiklikler var (%{category_score:.1f})")
                missing_criteria = [result.criteria_name for result in results.values() if not result.found]
                if missing_criteria:
                    recommendations.append(f"   Eksik: {', '.join(missing_criteria[:3])}")
            elif category_score < 70:
                recommendations.append(f"âš ï¸ {category}: GeliÅŸtirme gerekli (%{category_score:.1f})")
            else:
                recommendations.append(f"âœ… {category}: Yeterli (%{category_score:.1f})")
        
        return recommendations

    def analyze_file(self, file_path: str) -> Dict[str, Any]:
        """Ana dosya analiz fonksiyonu"""
        logger.info(f"Dosya analiz ediliyor: {file_path}")
        
        file_ext = os.path.splitext(file_path)[1].lower()
        text = ""
        ocr_text = ""
        visual_detections = []
        
        try:
            if file_ext == '.pdf':
                text = self.extract_text_from_pdf(file_path)
                # PDF'den gÃ¶rÃ¼ntÃ¼ Ã§Ä±karÄ±p OCR uygula
                try:
                    doc = fitz.open(file_path)
                    for page_num in range(min(3, len(doc))):
                        page = doc[page_num]
                        pix = page.get_pixmap()
                        img_data = pix.pil_tobytes(format="PNG")
                        img = Image.open(io.BytesIO(img_data))
                        img_array = np.array(img)
                        temp_path = f"temp_page_{page_num}.png"
                        cv2.imwrite(temp_path, cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
                        ocr_text += self.extract_text_from_image(temp_path) + " "
                        visual_detections.extend(self.detect_visual_components(temp_path))
                        os.remove(temp_path)
                    doc.close()
                except:
                    pass
                    
            elif file_ext in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp']:
                ocr_text = self.extract_text_from_image(file_path)
                visual_detections = self.detect_visual_components(file_path)
            else:
                return {"error": f"Desteklenmeyen dosya formatÄ±: {file_ext}"}
            
            if not text and not ocr_text:
                return {"error": "Dosyadan metin Ã§Ä±karÄ±lamadÄ±"}
            
            # Analiz yap
            analysis_results = {}
            for category in self.pneumatic_criteria_weights.keys():
                analysis_results[category] = self.analyze_criteria(text, ocr_text, visual_detections, category)
            
            scores = self.calculate_scores(analysis_results)
            extracted_values = self.extract_specific_values(text, ocr_text)
            project_info = self.extract_project_information(text, ocr_text)
            recommendations = self.generate_recommendations(analysis_results, scores, extracted_values)
            
            report = {
                "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "file_info": {
                    "file_path": file_path,
                    "file_type": file_ext,
                    "text_length": len(text),
                    "ocr_text_length": len(ocr_text),
                    "visual_components": len(visual_detections)
                },
                "project_information": project_info,
                "extracted_values": extracted_values,
                "category_analyses": analysis_results,
                "scoring": scores,
                "overall_score": {
                    "max_points": 100,
                    "percentage": scores["overall_percentage"],
                    "quality_level": self.get_quality_level(scores["overall_percentage"]),
                    "status": "PASS" if scores["overall_percentage"] >= 70 else "FAIL",
                    "status_tr": "GEÃ‡ERLÄ°" if scores["overall_percentage"] >= 70 else "GEÃ‡ERSÄ°Z",
                    "total_points": scores["overall_percentage"]
                },
                "recommendations": recommendations,
                "summary": {
                    "total_score": scores["total_score"],
                    "percentage": scores["overall_percentage"],
                    "status": "GEÃ‡ERLÄ°" if scores["overall_percentage"] >= 70 else "GEÃ‡ERSÄ°Z",
                    "quality_level": self.get_quality_level(scores["overall_percentage"])
                }
            }
            
            return report
            
        except Exception as e:
            logger.error(f"Analiz hatasÄ±: {e}")
            return {"error": str(e)}

    def get_quality_level(self, percentage: float) -> str:
        """Kalite seviyesi belirleme"""
        if percentage >= 90:
            return "MÃœKEMMEL"
        elif percentage >= 80:
            return "Ã‡OK Ä°YÄ°"
        elif percentage >= 70:
            return "Ä°YÄ°"
        elif percentage >= 60:
            return "ORTA"
        elif percentage >= 40:
            return "YETERSIZ"
        else:
            return "KÃ–TÃœ"

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def check_tesseract_installation():
    """Check if Tesseract is properly installed"""
    try:
        version = pytesseract.get_tesseract_version()
        logger.info(f"Tesseract OCR kurulu - SÃ¼rÃ¼m: {version}")
        return True, f"Tesseract v{version}"
    except Exception as e:
        logger.error(f"Tesseract OCR kurulu deÄŸil: {e}")
        return False, str(e)

tesseract_available, tesseract_info = check_tesseract_installation()

def validate_document_server(text, validation_keywords):
    """Server kodunda dokÃ¼man validasyonu - DB'den"""
    
    # DB'den critical_terms al
    critical_terms_data = validation_keywords.get('critical_terms', {})
    
    # Liste formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    critical_terms = []
    for key, value in critical_terms_data.items():
        if key.startswith('category_') and isinstance(value, list):
            critical_terms.append(value)
    
    if not critical_terms:
        logger.warning("âš ï¸ Critical terms bulunamadÄ±, validasyon atlanÄ±yor")
        return True
    
    category_found = []
    for i, category in enumerate(critical_terms):
        found_in_category = False
        for term in category:
            if re.search(rf"\b{term}\b", text, re.IGNORECASE):
                found_in_category = True
                logger.info(f"PnÃ¶matik Kategori {i+1} bulundu: '{term}'")
                break
        category_found.append(found_in_category)
    
    valid_categories = sum(category_found)
    logger.info(f"DokÃ¼man validasyonu: {valid_categories}/{len(critical_terms)} kritik kategori bulundu")
    
    return valid_categories >= len(critical_terms) - 1

def check_strong_keywords_first_pages(filepath, validation_keywords):
    """Ä°lk 1-2 sayfada Ã¶zgÃ¼ kelimeleri OCR ile ara - DB'den"""
    
    # DB'den strong keywords al
    strong_keywords = validation_keywords.get('strong_keywords', [])
    
    if not strong_keywords:
        logger.warning("âš ï¸ Strong keywords bulunamadÄ±, validasyon atlanÄ±yor")
        return True
    
    try:
        pages = pdf2image.convert_from_path(filepath, dpi=400, first_page=1, last_page=1)
        
        all_text = ""
        for i, page in enumerate(pages):
            opencv_image = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)
            processed = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            
            text = pytesseract.image_to_string(processed, config='--oem 3 --psm 3 -l tur+eng')
            all_text += text.lower() + " "
        
        found_keywords = []
        for keyword in strong_keywords:
            if re.search(rf"\b{keyword.lower()}\b", all_text):
                found_keywords.append(keyword)
        
        logger.info(f"Ä°lk sayfa kontrol: {len(found_keywords)} Ã¶zgÃ¼ kelime: {found_keywords}")
        return len(found_keywords) >= 1
        
    except Exception as e:
        logger.warning(f"Ä°lk sayfa kontrol hatasÄ±: {e}")
        return False

def check_excluded_keywords_first_pages(filepath, validation_keywords):
    """Ä°lk 1-2 sayfada istenmeyen rapor tÃ¼rlerinin kelimelerini ara - DB'den"""
    
    # DB'den excluded keywords al
    excluded_keywords = validation_keywords.get('excluded_keywords', [])
    
    if not excluded_keywords:
        logger.warning("âš ï¸ Excluded keywords bulunamadÄ±, validasyon atlanÄ±yor")
        return False
    
    try:
        pages = pdf2image.convert_from_path(filepath, dpi=200, first_page=1, last_page=1)
        
        all_text = ""
        for i, page in enumerate(pages):
            opencv_image = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)
            processed = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            
            text = pytesseract.image_to_string(processed, config='--oem 3 --psm 3 -l tur+eng')
            all_text += text.lower() + " "
        
        logger.info(f"OCR okunan text: {all_text[:500]}...")
        
        found_excluded = []
        for keyword in excluded_keywords:
            if re.search(rf"\b{keyword.lower()}\b", all_text):
                found_excluded.append(keyword)
        
        logger.info(f"Ä°lk sayfa excluded kontrol: {len(found_excluded)} istenmeyen kelime: {found_excluded}")
        return len(found_excluded) >= 1
        
    except Exception as e:
        logger.warning(f"Ä°lk sayfa excluded kontrol hatasÄ±: {e}")
        return False

def get_conclusion_message_pneumatic(status, percentage):
    """SonuÃ§ mesajÄ±nÄ± dÃ¶ndÃ¼r - PnÃ¶matik iÃ§in"""
    if status == "PASS":
        return f"PnÃ¶matik devre ÅŸemasÄ± ISO 5599 ve ilgili standartlara uygun ve teknik aÃ§Ä±dan yeterlidir (%{percentage:.0f})"
    elif status == "CONDITIONAL":
        return f"PnÃ¶matik devre ÅŸemasÄ± kabul edilebilir ancak bazÄ± eksiklikler var (%{percentage:.0f})"
    else:
        return f"PnÃ¶matik devre ÅŸemasÄ± standartlara uygun deÄŸil, kapsamlÄ± revizyon gerekli (%{percentage:.0f})"

def get_main_issues_pneumatic(analysis_result):
    """Ana sorunlarÄ± listele - PnÃ¶matik iÃ§in"""
    issues = []
    
    if 'scoring' in analysis_result and 'category_scores' in analysis_result['scoring']:
        for category, score_data in analysis_result['scoring']['category_scores'].items():
            if isinstance(score_data, dict) and score_data.get('percentage', 0) < 50:
                issues.append(f"{category} kategorisinde ciddi eksiklikler")
    
    if not issues:
        if analysis_result['summary']['total_score'] < 50:
            issues = [
                "PnÃ¶matik semboller ISO 5599 standardÄ±na uygun deÄŸil",
                "FRL Ã¼nitesi ve hava hazÄ±rlama eksik",
                "BasÄ±nÃ§ ve debi deÄŸerleri eksik veya hatalÄ±",
                "Vana tipleri ve kontrol sistemleri yetersiz",
                "GÃ¼venlik elemanlarÄ± ve acil durdurma eksik"
            ]
    
    return issues[:4]

# ============================================================================
# FLASK APP
# ============================================================================

app = Flask(__name__)

# Database configuration (YENÄ°)
app.config['SQLALCHEMY_DATABASE_URI'] = Config.SQLALCHEMY_DATABASE_URI
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = Config.SQLALCHEMY_TRACK_MODIFICATIONS
app.config['SQLALCHEMY_ECHO'] = Config.SQLALCHEMY_ECHO

PORT = int(os.environ.get('PORT', 8010))

UPLOAD_FOLDER = 'temp_uploads_pnomatic'
ALLOWED_EXTENSIONS = {'pdf', 'jpg', 'jpeg', 'png'}

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/api/pnomatic-control', methods=['POST'])
def analyze_pnomatic_control():
    """PnÃ¶matik Devre ÅemasÄ± analiz API endpoint'i - 3 AÅŸamalÄ± Validasyon"""
    try:
        if 'file' not in request.files:
            return jsonify({
                'error': 'No file provided',
                'message': 'LÃ¼tfen analiz edilmek Ã¼zere bir pnÃ¶matik devre ÅŸemasÄ± saÄŸlayÄ±n'
            }), 400

        file = request.files['file']

        if file.filename == '':
            return jsonify({
                'error': 'No file selected',
                'message': 'LÃ¼tfen bir dosya seÃ§in'
            }), 400

        if not allowed_file(file.filename):
            return jsonify({
                'error': 'Invalid file type',
                'message': 'Sadece PDF, JPG, JPEG ve PNG dosyalarÄ± kabul edilir'
            }), 400

        try:
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            logger.info(f"PnÃ¶matik Devre ÅemasÄ± kontrol ediliyor: {filename}")

            # Create analyzer instance with app context
            analyzer = PneumaticCircuitAnalyzer(app=app)
            
            logger.info(f"ÃœÃ§ aÅŸamalÄ± pnÃ¶matik kontrolÃ¼ baÅŸlatÄ±lÄ±yor: {filename}")
            file_ext = os.path.splitext(filepath)[1].lower()

            if file_ext == '.pdf':
                logger.info("AÅŸama 1: Ä°lk sayfa pnÃ¶matik Ã¶zgÃ¼ kelime kontrolÃ¼...")
                if check_strong_keywords_first_pages(filepath, analyzer.validation_keywords):
                    logger.info("âœ… AÅŸama 1 geÃ§ti - PnÃ¶matik Ã¶zgÃ¼ kelimeler bulundu")
                else:
                    logger.info("AÅŸama 2: Ä°lk sayfa excluded kelime kontrolÃ¼...")
                    if check_excluded_keywords_first_pages(filepath, analyzer.validation_keywords):
                        logger.info("âŒ AÅŸama 2'de excluded kelimeler bulundu - PnÃ¶matik deÄŸil")
                        try:
                            os.remove(filepath)
                        except:
                            pass
                        return jsonify({
                            'error': 'Invalid document type',
                            'message': 'Bu dosya pnÃ¶matik devre ÅŸemasÄ± deÄŸil (farklÄ± rapor tÃ¼rÃ¼ tespit edildi). LÃ¼tfen pnÃ¶matik devre ÅŸemasÄ± yÃ¼kleyiniz.',
                            'details': {
                                'filename': filename,
                                'document_type': 'OTHER_REPORT_TYPE',
                                'required_type': 'PNOMATIK_DEVRE_SEMASI'
                            }
                        }), 400
                    else:
                        logger.info("AÅŸama 3: Tam dokÃ¼man critical terms kontrolÃ¼...")
                        try:
                            with open(filepath, 'rb') as pdf_file:
                                pdf_reader = PyPDF2.PdfReader(pdf_file)
                                text = ""
                                for page in pdf_reader.pages:
                                    text += page.extract_text() + "\n"
                            
                            if not text or len(text.strip()) < 50:
                                try:
                                    os.remove(filepath)
                                except:
                                    pass
                                return jsonify({
                                    'error': 'Text extraction failed',
                                    'message': 'Dosyadan yeterli metin Ã§Ä±karÄ±lamadÄ±'
                                }), 400
                            
                            if not validate_document_server(text, analyzer.validation_keywords):
                                try:
                                    os.remove(filepath)
                                except:
                                    pass
                                return jsonify({
                                    'error': 'Invalid document type',
                                    'message': 'YÃ¼klediÄŸiniz dosya pnÃ¶matik devre ÅŸemasÄ± deÄŸil! LÃ¼tfen geÃ§erli bir pnÃ¶matik devre ÅŸemasÄ± yÃ¼kleyiniz.',
                                    'details': {
                                        'filename': filename,
                                        'document_type': 'NOT_PNEUMATIC_CIRCUIT',
                                        'required_type': 'PNOMATIK_DEVRE_SEMASI'
                                    }
                                }), 400
                                
                        except Exception as e:
                            logger.error(f"AÅŸama 3 hatasÄ±: {e}")
                            try:
                                os.remove(filepath)
                            except:
                                pass
                            return jsonify({
                                'error': 'Analysis failed',
                                'message': 'Dosya analizi sÄ±rasÄ±nda hata oluÅŸtu'
                            }), 500

            elif file_ext in ['.jpg', '.jpeg', '.png']:
                requires_ocr = True
                if requires_ocr and not tesseract_available:
                    try:
                        os.remove(filepath)
                    except:
                        pass
                    
                    return jsonify({
                        'error': 'OCR not available',
                        'message': 'Tesseract OCR kurulu deÄŸil. Resim dosyalarÄ±nÄ± analiz edebilmek iÃ§in Tesseract kurulumu gereklidir.',
                        'details': {
                            'tesseract_error': tesseract_info,
                            'file_type': file_ext,
                            'requires_ocr': True
                        }
                    }), 500

            logger.info(f"PnÃ¶matik devre ÅŸemasÄ± doÄŸrulandÄ±, analiz baÅŸlatÄ±lÄ±yor: {filename}")
            analysis_result = analyzer.analyze_file(filepath)
            
            try:
                os.remove(filepath)
                logger.info(f"Uploaded file {filename} cleaned up")
            except Exception as e:
                logger.warning(f"Could not remove uploaded file {filename}: {e}")

            if 'error' in analysis_result:
                return jsonify({
                    'error': 'Analysis failed',
                    'message': analysis_result['error'],
                    'details': {
                        'filename': filename,
                        'analysis_details': analysis_result.get('details', {})
                    }
                }), 400

            overall_percentage = analysis_result['summary']['percentage']
            status = "PASS" if overall_percentage >= 70 else "FAIL"
            
            response_data = {
                'analysis_date': analysis_result.get('analysis_date', datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
                'analysis_details': {
                    'found_criteria': len([r for results in analysis_result.get('scoring', {}).get('category_scores', {}).values() 
                                         for r in results if isinstance(r, dict) and r.get('found', False)]),
                    'total_criteria': len([r for results in analysis_result.get('scoring', {}).get('category_scores', {}).values() 
                                         for r in results if isinstance(r, dict)]),
                    'percentage': round(overall_percentage, 1)
                },
                'analysis_id': f"pneumatic_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'category_scores': {},
                'date_validity': {
                    'is_valid': True,
                    'message': 'PnÃ¶matik devre ÅŸemalarÄ± iÃ§in tarih geÃ§erliliÄŸi kontrolÃ¼ uygulanmaz',
                    'days_old': 0,
                    'formatted_date': 'N/A'
                },
                'extracted_values': analysis_result.get('extracted_values', {}),
                'file_type': 'PNOMATIK_DEVRE_SEMASI',
                'filename': filename,
                'language_info': {
                    'detected_language': 'turkish',
                    'file_type': file_ext.replace('.', '')
                },
                'overall_score': {
                    'percentage': round(overall_percentage, 2),
                    'total_points': analysis_result['summary']['total_score'],
                    'max_points': 100,
                    'status': status,
                    'status_tr': 'GEÃ‡ERLÄ°' if status == "PASS" else 'GEÃ‡ERSÄ°Z',
                    'quality_level': analysis_result['summary']['quality_level']
                },
                'recommendations': analysis_result.get('recommendations', []),
                'summary': {
                    'is_valid': status == "PASS",
                    'conclusion': get_conclusion_message_pneumatic(status, overall_percentage),
                    'main_issues': [] if status == "PASS" else get_main_issues_pneumatic(analysis_result)
                }
            }
            
            if 'scoring' in analysis_result and 'category_scores' in analysis_result['scoring']:
                for category, score_data in analysis_result['scoring']['category_scores'].items():
                    if isinstance(score_data, dict):
                        response_data['category_scores'][category] = {
                            'score': score_data.get('normalized', score_data.get('score', 0)),
                            'max_score': score_data.get('max_weight', score_data.get('max_score', 0)),
                            'percentage': score_data.get('percentage', 0),
                            'status': 'PASS' if score_data.get('percentage', 0) >= 70 else 'CONDITIONAL' if score_data.get('percentage', 0) >= 50 else 'FAIL'
                        }

            return jsonify({
                'analysis_service': 'pneumatic_circuit',
                'data': response_data,
                'message': 'PnÃ¶matik Devre ÅemasÄ± baÅŸarÄ±yla analiz edildi',
                'service_description': 'PnÃ¶matik Devre ÅemasÄ± Analizi',
                'service_port': PORT,
                'success': True
            })

        except Exception as analysis_error:
            try:
                if 'filepath' in locals():
                    os.remove(filepath)
            except:
                pass
            
            logger.error(f"Analiz hatasÄ±: {str(analysis_error)}")
            return jsonify({
                'error': 'Analysis failed',
                'message': f'PnÃ¶matik devre ÅŸemasÄ± analizi sÄ±rasÄ±nda hata oluÅŸtu: {str(analysis_error)}',
                'details': {
                    'error_type': type(analysis_error).__name__,
                    'file_processed': filename if 'filename' in locals() else 'unknown'
                }
            }), 500

    except Exception as e:
        logger.error(f"API endpoint hatasÄ±: {str(e)}")
        return jsonify({
            'error': 'Server error',
            'message': f'Sunucu hatasÄ±: {str(e)}'
        }), 500

@app.route('/api/pnomatic-health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'service': 'Pneumatic Circuit Diagram Analyzer API',
        'version': '1.0.0',
        'tesseract_available': tesseract_available,
        'tesseract_info': tesseract_info,
        'upload_folder': UPLOAD_FOLDER,
        'max_file_size_mb': app.config['MAX_CONTENT_LENGTH'] // (1024 * 1024),
        'supported_formats': list(ALLOWED_EXTENSIONS),
        'ocr_support': tesseract_available,
        'report_type': 'PNOMATIK_DEVRE_SEMASI'
    })

@app.route('/', methods=['GET'])
def index():
    """API bilgileri"""
    return jsonify({
        'service': 'Pneumatic Circuit Diagram Analyzer API',
        'version': '1.0.0',
        'description': 'PnÃ¶matik Devre ÅemalarÄ±nÄ± analiz eden REST API servisi',
        'endpoints': {
            'POST /api/pnomatic-control': 'PnÃ¶matik devre ÅŸemasÄ± analizi',
            'GET /api/pnomatic-health': 'Health check',
            'GET /': 'API info'
        },
        'usage': {
            'upload_format': 'multipart/form-data',
            'file_field': 'file',
            'supported_types': list(ALLOWED_EXTENSIONS),
            'max_size_mb': app.config['MAX_CONTENT_LENGTH'] // (1024 * 1024)
        }
    })

@app.errorhandler(413)
def too_large(e):
    return jsonify({
        'error': 'File too large',
        'message': 'Dosya boyutu 50MB limitini aÅŸÄ±yor'
    }), 413

@app.errorhandler(400)
def bad_request(e):
    return jsonify({
        'error': 'Bad request',
        'message': 'GeÃ§ersiz istek'
    }), 400

@app.errorhandler(500)
def internal_error(e):
    return jsonify({
        'error': 'Internal server error',
        'message': 'Sunucu hatasÄ± oluÅŸtu'
    }), 500

# ============================================
# DATABASE INITIALIZATION
# ============================================
with app.app_context():
    db.init_app(app)

# ============================================
# APPLICATION ENTRY POINT
# ============================================
if __name__ == '__main__':
    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
    
    logger.info("=" * 60)
    logger.info("PnÃ¶matik Devre ÅemasÄ± Analiz API")
    logger.info("=" * 60)
    logger.info(f"ğŸ“ Upload klasÃ¶rÃ¼: {UPLOAD_FOLDER}")
    logger.info(f"ğŸ“Š Desteklenen formatlar: {', '.join(ALLOWED_EXTENSIONS)}")
    logger.info(f"ğŸ“ Maksimum dosya boyutu: {app.config['MAX_CONTENT_LENGTH'] // (1024 * 1024)} MB")
    logger.info(f"ğŸ”§ Tesseract OCR: {'Kurulu' if tesseract_available else 'Kurulu deÄŸil'}")
    logger.info("")
    logger.info("ğŸ”— API Endpoints:")
    logger.info("  POST /api/pnomatic-control - PnÃ¶matik devre ÅŸemasÄ± analizi")
    logger.info("  GET  /api/pnomatic-health  - Health check")
    logger.info("  GET  /                     - API info")
    logger.info("=" * 60)
    
    port = int(os.environ.get('PORT', 8010))
    logger.info(f"ğŸš€ Servis baÅŸlatÄ±lÄ±yor - Port: {port}")
    logger.info("=" * 60)
    
    app.run(host='0.0.0.0', port=port, debug=False)